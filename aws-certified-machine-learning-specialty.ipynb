{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Certified Machine Learning - Specialty\n",
    "\n",
    "This notebooks include an outline of the key AWS services and techniques to know for the certification exam. More details please refer to AWS websites. Part of the materials can also be found from the **aws-cloud-practitioner-essentials notebooks** saved in this repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain 1: Data Engineering\n",
    "\n",
    "### AWS Kinesis\n",
    "#### Kinesis Streams\n",
    "- Use case: Real-time application\n",
    "- Streams limit \n",
    "    - Producer: 1MB/s or 1000 messages/s at write per shard\n",
    "    - Consumer: 2MB/s at read per shard and 5API calls per second per shard across all consumers\n",
    "    \n",
    "#### Kinesis Firehose\n",
    "- Use case: Data ingestion\n",
    "\n",
    "#### Kinesis Analytics\n",
    "- Use case: Streaming ETL, continuous metric generation, responsive analytics\n",
    "- Machine learning functions:\n",
    "    - RANDOM_CUT_FOREST fo anomaly detection\n",
    "    - HOTSPOTS\n",
    "    \n",
    "#### Kinesis Video Streams\n",
    "\n",
    "### Glue \n",
    "#### Glue Data Catelog, Glue Crawlers, Glue ETL\n",
    "- Glue ETL runs Run Apache Spark code\n",
    "\n",
    "### AWS Data Stores\n",
    "#### Redshift\n",
    "- Data warehouse\n",
    "- SQL analytics, OLAP - online analytical processing\n",
    "\n",
    "#### RDS, Aurora\n",
    "- Relational database\n",
    "- OLTP - Online Transaction Processing\n",
    "\n",
    "#### DynamoDB\n",
    "- NoSQL data store\n",
    "\n",
    "#### S3\n",
    "- Objectie store\n",
    "- S3 storage tiers\n",
    "- S3 encryption (using KMS)\n",
    "- S3 security (using relevant AWS services IAM policeis)\n",
    "\n",
    "#### ElasticSearch\n",
    "#### ElasticCache\n",
    "\n",
    "### AWS Data Pipeline\n",
    "- Orchestration service\n",
    "\n",
    "### AWS Batch\n",
    "- Run batch jobs as Docker images\n",
    "\n",
    "### AWS DMS (Database Migration Service)\n",
    "\n",
    "### AWS Step Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain 2: Exploratory Data Analysis\n",
    "### Amazon Athena\n",
    "- Pay-as-you-go: 5 dollar per TB scanned\n",
    "\n",
    "### Amazon QuickSight\n",
    "- Data visualization tool for everyone\n",
    "- 10 GB of super-fast, parallel, in-memory calculated (SPICE) engine\n",
    "- Machine learning features: anomaly detection, forecasting, auto-narratives\n",
    "\n",
    "### EMR (Elastic MapReduce)\n",
    "- Hadoop framework on EC2 instances\n",
    "- Nodes\n",
    "- Spark\n",
    "- Seppeline\n",
    "- EMR notebook\n",
    "- Instance types: m4.large if < 50 nodes, m4.xlarge if > 50 nodes for master node\n",
    "- Spot instances are good choice for task nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain 3: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain 4: Machine Learning Implementation and Operations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
