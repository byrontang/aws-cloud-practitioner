{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Cloud Practitioner Essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 1: Introduction to Amazon Web Services\n",
    "### Client-Server Model\n",
    "In computing, a **client** can be a web browser or desktop application that a person interacts with to make requests to computer servers. A **server** can be services such as *Amazon Elastic Compute Cloud (Amazon EC2), a type of virtual server*.\n",
    "\n",
    "For example, suppose that a client makes a request for a news article, the score in an online game, or a funny video. The server evaluates the details of this request and fulfills it by returning the information to the client.\n",
    "\n",
    "### Cloud Computing\n",
    "Cloud computing is the on-demand delivery of IT resources over the internet with pay-as-you-go pricing.\n",
    "- On-demand: anytime, flexible\n",
    "- IT resources: all kinds of products for undifferentiated heavy lifting of IT, tasks that are common, repeatetive, and time-comsuming.\n",
    "\n",
    "#### Deployment models for cloud computing\n",
    "The three cloud computing deployment models are **cloud-based, on-premises, and hybrid**. \n",
    "- On-premises deployment is also known as a private cloud deployment.\n",
    "- Hybrid deployment connects cloud-based resources to on-premises infrastructure and integrates cloud-based resources with legacy IT applications.\n",
    "\n",
    "#### Benefits of cloud computing\n",
    "- Trade upfront expense for variable expense\n",
    "- Stop spending money to run and maintain data centers (and focus more on your applications and customers)\n",
    "- Stop guessing capacity (pay-as-you-go)\n",
    "- Benefit from massive economies of scale\n",
    "- Increase speed and agility (Cloud computing enables you to access new resources within minutes.)\n",
    "- Go global in minutes (low latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2: Compute in the Cloud\n",
    "\n",
    "### Amazone Elastic Compute Cloud (Amazon EC2)\n",
    "\n",
    "[Amazon Elastic Compute Cloud (Amazon EC2)](https://aws.amazon.com/ec2/?ec2-whats-new.sort-by=item.additionalFields.postDateTime&ec2-whats-new.sort-order=desc) provides secure, resizable **compute capacity** in the cloud as Amazon EC2 instances. **Amazon EC2** offers the broadest and deepest compute platform with choice of processor, storage, networking, operating system, and purchase model.\n",
    "\n",
    "#### Note: Fundemantally, Amazon EC2 is a server, or a virtual machine, which is equivalent to the Azure Virtual Machines.\n",
    "\n",
    "#### Azazon EC2 instance types\n",
    "##### General purpose instances\n",
    "General purpose instances provide a balance of compute, memory, and networking resources.\n",
    "\n",
    "##### Compute optimized instances\n",
    "Compute optimized applications are ideal for ***high-performance web servers, compute-intensive applications servers, and dedicated gaming servers***. You can also use compute optimized instances for batch processing workloads that require processing many transactions in a single group.\n",
    "\n",
    "##### Momory optimized instances\n",
    "Memory optimized instances are designed to deliver fast performance for workloads that process large datasets **in memory**. In computing, memory is a temporary storage area. It holds all the data and instructions that a central processing unit (CPU) needs to be able to complete actions. Before a computer program or application is able to run, it is loaded from storage into memory. This preloading process gives the CPU direct access to the computer program.\n",
    "\n",
    "##### Accelerated computing instances\n",
    "Accelerated computing instances use hardware accelerators, or coprocessors, to perform some functions more efficiently than is possible in software running on CPUs. Examples of these functions include ***floating-point number calculations, graphics processing, and data pattern matching***.\n",
    "\n",
    "##### Storage optimized instances\n",
    "\n",
    "Storage optimized instances are designed for workloads that require high, sequential read and write access to large datasets on local storage. Examples of workloads suitable for storage optimized instances include ***distributed file systems, data warehousing applications, and high-frequency online transaction processing (OLTP) systems***. \n",
    "\n",
    "In computing, the term **input/output operations per second (IOPS)** is a metric that measures the performance of a storage device. It indicates how many different input or output operations a device can perform in one second. Storage optimized instances are designed to deliver tens of thousands of low-latency, random IOPS to applications.\n",
    "\n",
    "#### Amazon EC2 Pricing\n",
    "##### On-Demand\n",
    "On-Demand Instances are ideal for short-term, irregular workloads that cannot be interrupted. No upfront costs or minimum contracts apply. The instances run continuously until you stop them, and you pay for only the compute time you use.\n",
    "\n",
    "Sample use cases for On-Demand Instances include developing and testing applications and running applications that have unpredictable usage patterns. On-Demand Instances are not recommended for workloads that last a year or longer because these workloads can experience greater cost savings using Reserved Instances.\n",
    "\n",
    "##### Saving Plans\n",
    "Amazon EC2 Savings Plans enable you to reduce your compute costs by committing to a consistent amount of compute usage for a 1-year or 3-year term. This term commitment results in savings of up to 72% over On-Demand costs. Any usage up to the commitment is charged at the discounted Savings Plan rate (for example, 10 dollars an hour). Any usage beyond the commitment is charged at regular On-Demand rates.\n",
    "\n",
    "##### Reserved Instances\n",
    "Reserved Instances are a billing discount applied to the use of On-Demand Instances in your account. You can purchase Standard Reserved and Convertible Reserved Instances for a 1-year or 3-year term, and Scheduled Reserved Instances for a 1-year term. You realize greater cost savings with the 3-year option.\n",
    "\n",
    "##### Spot Instances\n",
    "Spot Instances are ideal for workloads with flexible start and end times, or that can withstand interruptions. Spot Instances use unused Amazon EC2 computing capacity and offer you cost savings at up to 90% off of On-Demand prices.\n",
    "\n",
    "##### Dedicated Hosts\n",
    "Dedicated Hosts are physical servers with Amazon EC2 instance capacity that is fully dedicated to your use. You can use your existing per-socket, per-core, or per-VM software licenses to help maintain license compliance. You can purchase On-Demand Dedicated Hosts and Dedicated Hosts Reservations. Of all the Amazon EC2 options that were covered, Dedicated Hosts are the most expensive.\n",
    "\n",
    "#### Scaling Amazon EC2\n",
    "**Scalability** involves beginning with only the resources you need and designing your architecture to automatically respond to changing demand by scaling out or in. If you wanted the scaling process to happen automatically, which AWS service would you use? The AWS service that provides this functionality for Amazon EC2 instances is **Amazon EC2 Auto Scaling**. \n",
    "\n",
    "Within Amazon EC2 Auto Scaling, you can use two approaches: dynamic scaling and predictive scaling.\n",
    "\n",
    "- **Dynamic scaling** responds to changing demand. \n",
    "- **Predictive scaling** automatically schedules the right number of Amazon EC2 instances based on predicted demand.\n",
    "\n",
    "To scale faster, you can use dynamic scaling and predictive scaling together.\n",
    "\n",
    "##### Example: Amazon EC2 Auto Scaling\n",
    "When you create an **Auto Scaling group**, you can set the **minimum number** of Amazon EC2 instances. The minimum capacity is the number of Amazon EC2 instances that launch immediately after you have created the Auto Scaling group. In this example, the Auto Scaling group has a minimum capacity of one Amazon EC2 instance.\n",
    "\n",
    "Next, you can set the **desired capacity** at two Amazon EC2 instances even though your application needs a minimum of a single Amazon EC2 instance to run. *If you do not specify the desired number of Amazon EC2 instances in an Auto Scaling group, the desired capacity defaults to your minimum capacity.*\n",
    "\n",
    "The third configuration that you can set in an Auto Scaling group is the **maximum capacity**. For example, you might configure the Auto Scaling group to scale out in response to increased demand, but only to a maximum of four Amazon EC2 instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Load Balancing (ELB)\n",
    "\n",
    "A load balancer is an application that takes in requests and routes them to the instances to be processed. **Elastic Load Balancing** is the AWS service that automatically distributes incoming application traffic across multiple resources, such as Amazon EC2 instances. A load balancer acts as a single point of contact for all incoming web traffic to your Auto Scaling group. This means that as you add or remove Amazon EC2 instances in response to the amount of incoming traffic, these requests route to the load balancer first. Then, the requests spread across multiple resources that will handle them.\n",
    "\n",
    "ELB is automatically scalable. As your traffic grows, ELB is designed to handle the additional throughput with no change to the hourly cost. When your EC2 fleet auto-scales out, as each instance comes online, the auto-scaling service just lets the Elastic Load Balancing service know that it's ready to handle the traffic, and off it goes. Once the fleet scales in, ELB first stops all new traffic, and waits for the existing requests to complete, to drain out. Once they do that, then the auto-scaling engine can terminate the instances without disruption to existing customers. \n",
    "\n",
    "Well, we solve the back end traffic chaos with an ELB as well. Because ELB is regional, it's a single URL that each front end instance uses. Then the ELB directs traffic to the back end that has the least outstanding requests. Now, if the back end scales, once the new instance is ready, it just tells the ELB that it can take traffic, and it gets to work. The front end doesn't know and doesn't care how many back end instances are running. This is true decoupled architecture.\n",
    "\n",
    "### Messaging and Queuing\n",
    "\n",
    "*This idea of placing messages into a buffer is called **messaging and queuing***. Just as our cashier sends orders to the barista, applications send messages to each other to communicate. If applications communicate directly like our cashier and barista previously, this is called being **tightly coupled**. This type of architecture can be considered a **monolithic application**. A hallmark trait of a tightly coupled architecture is where if a single component fails or changes, it causes issues for other components or even the whole system. \n",
    "\n",
    "A more reliable architecture is **loosely coupled**. In a **microservices** approach, application components are loosely coupled. This is an architecture where if one component fails, it is isolated and therefore won't cause cascading failures throughout the whole system. In this case, if a single component fails, the other components continue to work because they are communicating with each other. The loose coupling prevents the entire application from failing. **Message Queue** is a buffer between applications in the loosely-coupled architecture.\n",
    "\n",
    "#### Amazon services for messaging and queuing\n",
    "**Amazon Simple Queue Service (Amazon SQS)** is a message queuing service. Using Amazon SQS, you can send, store, and receive messages between software components, without losing messages or requiring other services to be available. In Amazon SQS, an application sends messages into a queue. A user or service retrieves a message from the queue, processes it, and then deletes it from the queue.\n",
    "\n",
    "**Amazon Simple Notification Service (Amazon SNS)** is a publish/subscribe service. Using Amazon SNS topics, a publisher publishes messages to subscribers. This is similar to the coffee shop; the cashier provides coffee orders to the barista who makes the drinks. In Amazon SNS, subscribers can be web servers, email addresses, AWS Lambda functions, or several other options. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional compute services\n",
    "\n",
    "#### Serverless Computing\n",
    "The term “serverless” means that your code runs on servers, but you do not need to provision or manage these servers. Serverless means that you cannot actually see or access the underlying infrastructure or instances that are hosting your application. Instead, all the management of the underlying environment from a provisioning, scaling, high availability, and maintenance perspective are taken care of for you. All you need to do is focus on your application and the rest is taken care of. \n",
    "\n",
    "**AWS Lambda** is a service that lets you run code without needing to provision or manage servers. \n",
    "\n",
    "While using AWS Lambda, you **pay only for the compute time that you consume**. Charges apply only when your code is running. You can also run code for virtually any type of application or backend service, all with zero administration. \n",
    "\n",
    "For example, a simple Lambda function might involve automatically resizing uploaded images to the AWS Cloud. In this case, the function triggers when uploading a new image. \n",
    "\n",
    "#### Containers\n",
    "A container is a package for your code where you package up your application, its dependencies as well as any configurations that it needs to run. Containers provide you with a standard way to package your application's code and dependencies into a single object. You can also use containers for processes and workflows in which there are essential requirements for security, reliability, and scalability.\n",
    "\n",
    "When running containerized applications, it’s important to consider scalability. Suppose that instead of a single host with multiple containers, you have to manage tens of hosts with hundreds of containers. Alternatively, you have to manage possibly hundreds of hosts with thousands of containers.\n",
    "\n",
    "[**Amazon Elastic Container Service (Amazon ECS)**](https://aws.amazon.com/ecs/?whats-new-cards.sort-by=item.additionalFields.postDateTime&whats-new-cards.sort-order=desc&ecs-blogs.sort-by=item.additionalFields.createdDate&ecs-blogs.sort-order=desc) is a highly scalable, high-performance container management system that enables you to run and scale containerized applications on AWS. \n",
    "\n",
    "- Amazon ECS supports **Docker containers**. Docker is a software platform that enables you to build, test, and deploy applications quickly. AWS supports the use of open-source Docker Community Edition and subscription-based Docker Enterprise Edition. With Amazon ECS, you can use API calls to launch and stop Docker-enabled applications.\n",
    "\n",
    "**Amazon Elastic Kubernetes Service (Amazon EKS)** is a fully managed service that you can use to run Kubernetes on AWS. \n",
    "\n",
    "- **Kubernetes** is open-source software that enables you to deploy and manage containerized applications at scale. A large community of volunteers maintains Kubernetes, and AWS actively works together with the Kubernetes community. As new features and functionalities release for Kubernetes applications, you can easily apply these updates to your applications managed by Amazon EKS.\n",
    "\n",
    "**AWS Fargate** is a **serverless compute engine for containers**. It works with both Amazon ECS and Amazon EKS. When using AWS Fargate, you do not need to provision or manage servers. AWS Fargate manages your server infrastructure for you. You can focus more on innovating and developing your applications, and you pay only for the resources that are required to run your containers.\n",
    "\n",
    "\n",
    "#### Virtual Machine vs Functions vs Containers on AWS\n",
    "If you are trying to **host traditional applications** and want full access to the underlying operating system like Linux or Windows, you are going to want to use **EC2**. \n",
    "\n",
    "If you are looking to host **short running functions**, service-oriented or event driven applications and you don't want to manage the underlying environment at all, look into the **serverless AWS Lambda**. \n",
    "\n",
    "If you are looking to run Docker **container-based workloads on AWS**, \n",
    "- you first need to choose your orchestration tool. Do you want to use **Amazon ECS** or **Amazon EKS**? \n",
    "- After you choose your tool, you then need to chose your platform. Do you want to run your containers **on EC2 instances that you manage** or in a **serverless environment like AWS Fargate that is managed for you**? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
